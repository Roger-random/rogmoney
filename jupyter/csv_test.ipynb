{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a6e4562-3558-4f4d-9d6b-41acdd617be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659 items to 227 vendors in 28 categories after adding ./data/2016.csv, ignored 0\n",
      "1277 items to 326 vendors in 31 categories after adding ./data/2017.csv, ignored 12\n",
      "1825 items to 378 vendors in 35 categories after adding ./data/2018.csv, ignored 0\n",
      "2366 items to 431 vendors in 39 categories after adding ./data/2019.csv, ignored 21\n",
      "2695 items to 458 vendors in 40 categories after adding ./data/2020.csv, ignored 0\n",
      "3139 items to 490 vendors in 40 categories after adding ./data/2021.csv, ignored 0\n",
      "3470 items to 507 vendors in 40 categories after adding ./data/2022.csv, ignored 0\n",
      "3857 items to 531 vendors in 41 categories after adding ./data/2023.csv, ignored 31\n",
      "4049 items to 548 vendors in 43 categories after adding ./data/2024.csv, ignored 0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "csv_list = ('./data/2016.csv', \n",
    "            './data/2017.csv',\n",
    "            './data/2018.csv',\n",
    "            './data/2019.csv',\n",
    "            './data/2020.csv',\n",
    "            './data/2021.csv',\n",
    "            './data/2022.csv',\n",
    "            './data/2023.csv',\n",
    "            './data/2024.csv')\n",
    "\n",
    "vendors = list()\n",
    "categories = list()\n",
    "parsed_list = list()\n",
    "\n",
    "vendor_replace = {\n",
    "    \"888 Seafood\":\"888 Seafood Restaurant\",\n",
    "    \"888 Seafood Rest.\":\"888 Seafood Restaurant\",\n",
    "    \"99 Cent Only\":\"99 Cents Only\",\n",
    "    \"99 cent store\":\"99 Cents Only\",\n",
    "    \"99 cents only\":\"99 Cents Only\",\n",
    "    \"AT&T Mobility\":\"AT&T\",\n",
    "    \"ATT\":\"AT&T\",\n",
    "    \"Akin\":\"Akin AI\",\n",
    "    \"Bella Sera\":\"Bella Sera Trattoria\",\n",
    "    \"Borneo\":\"Borneo Kalimantan Cuisine\",\n",
    "    \"Borneo Kalamatan\":\"Borneo Kalimantan Cuisine\",\n",
    "    \"Borneo Kalamatian\":\"Borneo Kalimantan Cuisine\",\n",
    "    \"Borneo Kalimantan\":\"Borneo Kalimantan Cuisine\",\n",
    "    \"Borneo Kalimatan\":\"Borneo Kalimantan Cuisine\",\n",
    "    \"Boudin\":\"Boudin Bakery\",\n",
    "    \"Boudin SF\":\"Boudin Bakery\",\n",
    "    \"Chairman\":\"The Chairman\",\n",
    "    \"Charter\":\"Charter Communications\",\n",
    "    \"Charter Comm.\":\"Charter Communications\",\n",
    "    \"Claros\":\"Claro's\",\n",
    "    \"Costco Gas\":\"Costco\",\n",
    "    \"Costco Optical\":\"Costco\",\n",
    "    \"Costco gas\":\"Costco\",\n",
    "    \"DipYourCar.com\":\"DipYourCar\",\n",
    "    \"Disney Plus\":\"Disney\",\n",
    "    \"Disney Store\":\"Disney\",\n",
    "    \"Disney+\":\"Disney\",\n",
    "    \"Dreamhost\":\"DreamHost\",\n",
    "    \"Du-Par's\":\"Du-Par's Restaurant & Bakery\",\n",
    "    \"Du-Pars\":\"Du-Par's Restaurant & Bakery\",\n",
    "    \"Dupars\":\"Du-Par's Restaurant & Bakery\",\n",
    "    \"EPWC\":\"East Pasadena Water Company\",\n",
    "    \"East Pasadena Water Co\":\"East Pasadena Water Company\",\n",
    "    \"Fi\":\"Google Fi\",\n",
    "    \"Project Fi\":\"Google Fi\",\n",
    "    \"First Tech MC\":\"First Tech Federal Credit Union\",\n",
    "    \"First Tech Federal\":\"First Tech Federal Credit Union\",\n",
    "    \"FirstTechFed\":\"First Tech Federal Credit Union\",\n",
    "    \"Giggle\":\"Giggle Fiber\",\n",
    "    \"H-Mart\":\"H Mart\",\n",
    "    \"Hackaday\":\"Supplyframe\",\n",
    "    \"In-N-Out\":\"In-N-Out Burger\",\n",
    "    \"Intuit TurboTax\":\"Intuit\",\n",
    "    \"Kaiser Permanante\":\"Kaiser Permanente\",\n",
    "    \"Kleer Dental\":\"Kleer\",\n",
    "    \"Kee Wah\":\"Kee Wah Bakery\",\n",
    "    \"Kungfu Dumplings\":\"Kung Fu Dumplings\",\n",
    "    \"Kungfu Fried Dumplings\":\"Kung Fu Dumplings\",\n",
    "    \"Lao Xi\":\"Lao Xi Noodle House\",\n",
    "    \"Lao Xi Noodle\":\"Lao Xi Noodle House\",\n",
    "    \"Laoxi Noodle House\":\"Lao Xi Noodle House\",\n",
    "    \"Laoxi Noodles\":\"Lao Xi Noodle House\",\n",
    "    \"Lola's\":\"Lola's Peruvian\",\n",
    "    \"Love Letter Pizza Chicken\":\"Love Letter Pizza & Chicken\",\n",
    "    \"New Mandarin\":\"New Mandarin Noodle Deli\",\n",
    "    \"New Mandarin Noodle\":\"New Mandarin Noodle Deli\",\n",
    "    \"Oo Kook\":\"Oo-Kook\",\n",
    "    \"Phoenix\":\"Phoenix Kitchen\",\n",
    "    \"Pitfire\":\"Pitfire Pizza\",\n",
    "    \"Ralph's\":\"Ralphs\",\n",
    "    \"Robotis USA\":\"Robotis\",\n",
    "    \"RockAuto.com\":\"RockAuto\",\n",
    "    \"Scotty's\":\"Scotty's Automotive\",\n",
    "    \"Scotty's Brake & Muffler\":\"Scotty's Automotive\",\n",
    "    \"Sevenstock\":\"SevenStock\",\n",
    "    \"SoCal Gas\":\"SoCalGas\",\n",
    "    \"SoCal Linux Expo\":\"SCaLE\",\n",
    "    \"SupplyFrame\":\"Supplyframe\",\n",
    "    \"Temple City Dental\":\"Temple City Dental Care\",\n",
    "    \"TurboTax\":\"Intuit\",\n",
    "    \"Wikipedia\":\"Wikimedia Foundation\",\n",
    "    \"WM\":\"Waste Management\",\n",
    "    \"WordPress.com\":\"WordPress\",\n",
    "}\n",
    "\n",
    "category_replace = {\n",
    "    \"Airfare\":\"Transportation\",\n",
    "    \"Auto (non-gasoline)\":\"Automotive\",\n",
    "    \"Appliance\":\"Durable\",\n",
    "    \"Car\":\"Automotive\",\n",
    "    \"Communic.\":\"Communication\",\n",
    "    \"Consumables\":\"Consumable\",\n",
    "    \"Digital Purchase\":\"Digital\",\n",
    "    \"Health\":\"Healthcare\",\n",
    "    \"Hotel\":\"Lodging\",\n",
    "    \"Public Trasit\":\"Transportation\",\n",
    "    \"Tax-exempt grocery\":\"Groceries\",\n",
    "    \"Taxed Groceries\":\"Alcohol\",\n",
    "    \"Utilities\":\"Utility\",\n",
    "}\n",
    "\n",
    "def data_entry_error_vendor_correction(vendor_name):\n",
    "    if vendor_name in vendor_replace:\n",
    "        return vendor_replace[vendor_name]\n",
    "    return vendor_name\n",
    "\n",
    "def data_entry_error_category_correction(category_name):\n",
    "    if category_name in category_replace:\n",
    "        return category_replace[category_name]\n",
    "    return category_name\n",
    "\n",
    "for filename in csv_list:\n",
    "    ignored_count = 0\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        cd = csv.DictReader(csvfile)\n",
    "        for row in cd:\n",
    "            parsed = {}\n",
    "            for column, data in row.items():\n",
    "                data = data.strip()\n",
    "                if len(data) > 0:\n",
    "                    if column.endswith('Date'):\n",
    "                        parsed['Date'] = data\n",
    "                    elif column == 'Vendor':\n",
    "                        # Fix up data entry errors\n",
    "                        data = data_entry_error_vendor_correction(data)\n",
    "                        if data not in vendors:\n",
    "                            vendors.append(data)\n",
    "                        parsed['Vendor'] = data\n",
    "                    else:\n",
    "                        # Fix up data entry errors\n",
    "                        column = data_entry_error_category_correction(column)\n",
    "                        if column not in categories:\n",
    "                            categories.append(column)\n",
    "                        parsed[column]=float(data)\n",
    "            if len(parsed) >= 3:\n",
    "                parsed_list.append(parsed)\n",
    "            else:\n",
    "                ignored_count += 1\n",
    "    print(\"{} items to {} vendors in {} categories after adding {}, ignored {}\".format(len(parsed_list), len(vendors), len(categories), filename, ignored_count))\n",
    "\n",
    "vendors.sort()\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869af7b7-012a-44a1-94c0-7525ffc53a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4467 items in 4049 transactions\n"
     ]
    }
   ],
   "source": [
    "# Break down each line into two tables: transaction and one or more items for a transaction\n",
    "\n",
    "transactions = list()\n",
    "\n",
    "countdown=25\n",
    "transaction_id = 0\n",
    "transaction_items = list()\n",
    "transaction_item_id = 0\n",
    "\n",
    "for p in parsed_list:\n",
    "    transaction_total = 0\n",
    "\n",
    "    for key,value in p.items():\n",
    "        if key != 'Date' and key != 'Vendor':\n",
    "            transaction_total += value\n",
    "            transaction_items.append({\n",
    "                \"transaction_item_id\" : transaction_item_id,\n",
    "                \"transaction_id\" : transaction_id,\n",
    "                \"price\" : value,\n",
    "                \"quantity\" : 1,\n",
    "                \"category_id\" : categories.index(key),\n",
    "            })\n",
    "            transaction_item_id += 1\n",
    "                \n",
    "    transactions.append({\n",
    "        \"transaction_id\" : transaction_id,\n",
    "        \"date\" : p['Date'],\n",
    "        'vendor_id' : vendors.index(p['Vendor']),\n",
    "        'total' : transaction_total,\n",
    "    })\n",
    "    transaction_id += 1\n",
    "\n",
    "print(\"{} items in {} transactions\".format(len(transaction_items),len(transactions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5564425-cc7a-42bf-9406-7f0e870ed01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give every item a number as primary key. Might be something auto-generate-able in SQL\n",
    "\n",
    "vendors_list = list()\n",
    "for index, vendor in enumerate(vendors):\n",
    "    vendors_list.append({\n",
    "        \"vendor_id\" : index,\n",
    "        \"name\" : vendor\n",
    "    })\n",
    "\n",
    "categories_list = list()\n",
    "for index, category in enumerate(categories):\n",
    "    categories_list.append({\n",
    "        \"category_id\" : index,\n",
    "        \"category\" : category\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf343cb0-281a-4705-bfef-f8f5a0fd5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each CSV corresponds to how I think a SQL table should look\n",
    "\n",
    "def write_my_csv(data_list, data_name):\n",
    "    headers = list()\n",
    "    for key,value in data_list[0].items():\n",
    "        headers.append(key)\n",
    "    \n",
    "    with open('./data/{}.csv'.format(data_name),'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    \n",
    "        writer.writeheader()\n",
    "        for data in data_list:\n",
    "            writer.writerow(data)\n",
    "\n",
    "write_my_csv(vendors_list, 'vendors')\n",
    "write_my_csv(transactions, 'transactions')\n",
    "write_my_csv(categories_list, 'categories')\n",
    "write_my_csv(transaction_items, 'transaction_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9579125-86d4-427c-849b-ddc866cc3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# And now, a different experiment: building a single consolidated JSON for the\n",
    "# non-SQL databases. Each entry of the top-level list represent a transaction,\n",
    "# and it embeds another list of items within each transaction. (Usually just a\n",
    "# single element.)\n",
    "# Date and Vendor name are extracted straight out of parsed list\n",
    "# Items is sub-list of every other column.\n",
    "# Total is calculated from Items.\n",
    "consolidated_json = list()\n",
    "\n",
    "for original_line in parsed_list:\n",
    "    line_total = 0\n",
    "    original_items = list()\n",
    "    for key,value in original_line.items():\n",
    "        if key != 'Date' and key != 'Vendor':\n",
    "            line_total += value\n",
    "            original_items.append({\n",
    "                \"Price\" : value,\n",
    "                \"Category\" : key,\n",
    "            })\n",
    "    consolidated_json.append({\n",
    "        \"Date\" : original_line['Date'],\n",
    "        \"Vendor\" : original_line['Vendor'],\n",
    "        \"Total\" : line_total,\n",
    "        \"Items\" : original_items,\n",
    "    })\n",
    "\n",
    "import json\n",
    "with open('./data/consolidated.json','w',newline='') as f:\n",
    "    json.dump(consolidated_json, f, ensure_ascii=True, allow_nan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d143208-86ad-4c6c-b73f-e4e37f4386c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
